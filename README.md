# Libra Guardï¼šé¢å‘ä¸­æ–‡å¤§æ¨¡å‹çš„å®‰å…¨æŠ¤æ æ¨¡å‹ (Libra Guard: Large Chinese-based Safeguard for AI Content)

**Libra Guard** æ˜¯ä¸€æ¬¾é¢å‘ä¸­æ–‡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å®‰å…¨æŠ¤æ æ¨¡å‹ã€‚Libra Guard é‡‡ç”¨ä¸¤é˜¶æ®µæ¸è¿›å¼è®­ç»ƒæµç¨‹ï¼Œå…ˆåˆ©ç”¨å¯æ‰©å±•çš„åˆæˆæ ·æœ¬é¢„è®­ç»ƒï¼Œå†ä½¿ç”¨é«˜è´¨é‡çœŸå®æ•°æ®è¿›è¡Œå¾®è°ƒï¼Œæœ€å¤§åŒ–åˆ©ç”¨æ•°æ®å¹¶é™ä½å¯¹äººå·¥æ ‡æ³¨çš„ä¾èµ–ï¼Œå¹¶æ„å»ºäº†é¦–ä¸ªé’ˆå¯¹ä¸­æ–‡ LLM çš„å®‰å…¨åŸºå‡† â€”â€” **Libra Bench**ã€‚å®éªŒè¡¨æ˜ï¼ŒLibra Guard åœ¨ Libra Bench ä¸Šçš„è¡¨ç°æ˜¾è‘—ä¼˜äºåŒç±»å¼€æºæ¨¡å‹ï¼ˆå¦‚ ShieldLMç­‰ï¼‰ï¼Œåœ¨å¤šä¸ªä»»åŠ¡ä¸Šå¯ä¸å…ˆè¿›å•†ç”¨æ¨¡å‹ï¼ˆå¦‚ GPT-4oï¼‰æ¥è¿‘ï¼Œä¸ºä¸­æ–‡ LLM çš„å®‰å…¨æ²»ç†æä¾›äº†æ›´å¼ºçš„æ”¯æŒä¸è¯„æµ‹å·¥å…·ã€‚

*Libra Guard is a safeguard model for Chinese large language models (LLMs). Libra Guard adopts a two-stage progressive training process: first, it uses scalable synthetic samples for pretraining, then employs high-quality real-world data for fine-tuning, thus maximizing data utilization while reducing reliance on manual annotation and introduces the first comprehensive benchmark for Chinese LLM safetyâ€”**Libra Bench**. Experiments show that Libra Guard significantly outperforms similar open-source models (such as ShieldLM) on Libra Bench and is close to advanced commercial models (such as GPT-4o) in multiple tasks, providing stronger support and evaluation tools for Chinese LLM safety governance.  This project also provides complete usage examples, including scripts for single-machine and multi-machine inference, to facilitate researchers and developers in evaluating and improving model safety.*

---



## âœ¨ ä¸»è¦ç‰¹æ€§ (Key Features)

1. **ä¸¤é˜¶æ®µè¯¾ç¨‹å¼è®­ç»ƒ**ï¼šå…ˆåˆ©ç”¨å¯æ‰©å±•çš„åˆæˆæ ·æœ¬è¿›è¡Œé¢„è®­ç»ƒï¼Œå†ç”¨çœŸå®æ•°æ®å¾®è°ƒï¼Œåœ¨å‡å°‘äººå·¥æ ‡æ³¨ä¾èµ–çš„åŒæ—¶æå‡æ¨¡å‹è¡¨ç°ã€‚  
   *Two-stage curriculum training: pretraining on synthetic adversarial data, then fine-tuning on real-world examples, reducing reliance on manual annotations while improving performance.*

2. **å¯æ‰©å±•æ•°æ®æµç¨‹**ï¼šç»“åˆçœŸå®ä¸åˆæˆæ•°æ®ï¼Œå‡å°‘äººå·¥æ ‡æ³¨å·¥ä½œé‡å¹¶å¹¿æ³›è¦†ç›–æ½œåœ¨å®‰å…¨é£é™©ã€‚  
   *Scalable data pipeline: combining real-world and synthetic data to reduce annotation workloads and comprehensively cover possible safety risks.*

3. **é«˜æ€§èƒ½è¡¨ç°**ï¼šåœ¨å‡†ç¡®ç‡ä¸Šæ˜¾è‘—ä¼˜äºå…¶å®ƒå¼€æºæ¨¡å‹ï¼Œå¯¹æ¯”é—­æºæ¨¡å‹äº¦å…·æœ‰ç«äº‰åŠ›ã€‚  
   *High performance: significantly surpasses other open-source guard systems in accuracy, remaining competitive with closed-source models.*

4. **Libra Bench**ï¼šé¦–ä¸ªä¸­æ–‡å¤§æ¨¡å‹å®‰å…¨è¯„æµ‹åŸºå‡†ï¼Œæ¶µç›–ä¸ƒå¤§å…³é”®é£é™©åœºæ™¯å’Œ 5,700+ æ¡ä¸“å®¶æ ‡æ³¨æ•°æ®ã€‚  
   *Libra Bench: the first safety benchmark tailored for Chinese LLMs, covering seven critical harm scenarios with over 5,700 expert-annotated samples.*
---

## ğŸ å¿«é€Ÿå¼€å§‹ (Getting Started)

ä¸‹é¢åˆ—å‡ºäº†ä½¿ç”¨æœ¬é¡¹ç›®åŠå…¶æä¾›çš„è„šæœ¬è¿›è¡Œæ¨ç†ä¸è¯„æµ‹çš„ç®€è¦æ­¥éª¤ã€‚

*Below are the essential steps for using this project and its provided scripts for inference and evaluation.*

### ğŸ› ï¸ ç¯å¢ƒå®‰è£… (Installation)

1. å…‹éš†æœ¬ä»“åº“ï¼š  
   ```bash
   git clone https://github.com/caskcsg/Libra.git
   cd Libra
   ```
2. å®‰è£…ä¾èµ–ï¼š  
   ```bash
   pip install -r requirements.txt
   ```
---

## ğŸ“¥ æ•°æ®åŠ è½½ä¸æ ¼å¼ (Data Loading & Format)

æ‚¨å¯ä»¥ä» Hugging Face Hubä¸‹è½½å¹¶åŠ è½½ **Libra Bench** æ•°æ®é›†ï¼Œæ ¼å¼å¦‚ä¸‹æ‰€ç¤ºã€‚  
*You may download and load the **Libra Bench** dataset from the Hugging Face Hub, formatted as follows.*

```json
{
  "source": "queryæ¥æº",
  "category_name": "queryæœ‰å®³ç±»åˆ«",
  "question": "query",
  "response": "response",
  "label": "å®‰å…¨æ ‡ç­¾",
  "analyze": "å®‰å…¨åˆ†æ",
  "id": "id"
}
```


---

## ğŸ¤– æ¨ç†ä¸è¯„æµ‹ (Inference & Evaluation)

æœ¬é¡¹ç›®æä¾›äº†å¦‚ä¸‹è„šæœ¬ç¤ºä¾‹ï¼Œå¸®åŠ©æ‚¨åœ¨æœ¬åœ°ç¯å¢ƒä¸­å®Œæˆæ¨ç†ï¼š
*This project provides following example script to facilitate local inference: *



è„šæœ¬åä¸º `inference.py`ï¼Œå…¶ä¸»è¦å‚æ•°å¦‚ä¸‹ï¼š  
*The script is named `inference.py`; its main parameters are listed below:*

| å‚æ•° (Parameter)     | ç±»å‹ (Type) | é»˜è®¤å€¼ (Default) | è¯´æ˜ (Description)                                                                   |
|----------------------|-------------|------------------|--------------------------------------------------------------------------------------|
| `--base_model`       | str         | (å¿…å¡« Required)  | æŒ‡å®šæ¨¡å‹è·¯å¾„æˆ–åç§°ï¼Œå¦‚ `./models/Libra-Guard-7B`                                    |
| `--data_path`        | str         | (å¿…å¡« Required)  | æŒ‡å®šå¾…æ¨ç†æˆ–è¯„æµ‹çš„æ•°æ®æ–‡ä»¶ï¼ˆJSON / Parquet / æ–‡ä»¶å¤¹ï¼‰                                |
| `--batch_size`       | int         | 1                | æ¨ç†æ‰¹å¤§å°ï¼Œè§† GPU æ˜¾å­˜å’Œæ•°æ®é‡é€‚å½“è°ƒæ•´                                               |
| `--seed`             | int         | 42               | éšæœºç§å­ï¼Œä¿è¯ç»“æœå¯å¤ç°                                                              |
| `--out_path`         | str         | `./outputs`      | æ¨ç†ç»“æœä¿å­˜è·¯å¾„                                                                     |
| `--num_itera`        | int         | 1                | å¤šæ¬¡ç”Ÿæˆæˆ–å¯¹æ¯”æµ‹è¯•æ—¶å¯è®¾ç½®ä¸º >1ï¼Œä¸€èˆ¬é»˜è®¤ 1                                          |
| `--few_shot`         | int         | 0                | few-shot ç¤ºä¾‹æ•°ï¼Œå¦‚ >0 åˆ™åœ¨è¾“å…¥å‰æ·»åŠ æ¼”ç¤ºç¤ºä¾‹                                         |
| `--is_instruct`      | int         | 0                | æ˜¯å¦é‡‡ç”¨æŒ‡ä»¤é£æ ¼æ¨ç†ï¼ˆå¯ç”¨ Instruct æ¨¡æ¿ï¼‰                                           |
| `--machine_rank`     | int         | 0                | å½“å‰èŠ‚ç‚¹åºå·ï¼ˆåˆ†å¸ƒå¼æ—¶ä½¿ç”¨ï¼‰                                                          |
| `--machine_num`      | int         | 1                | èŠ‚ç‚¹æ€»æ•°ï¼ˆåˆ†å¸ƒå¼æ—¶ä½¿ç”¨ï¼‰                                                              |



**ä½¿ç”¨ç¤ºä¾‹ï¼š**  
*Usage example:*

```bash
# å•æœºå•å¡åœºæ™¯
python inference.py \
  --base_model ./models/Libra-Guard-7B \
  --data_path ./data/test.json \
  --batch_size 2 \
  --out_path ./outputs \
  --seed 42
```

---

## ğŸ“Š å®éªŒç»“æœ (Experimental Results)

åœ¨ä»¥ä¸‹è¡¨æ ¼ä¸­ï¼Œæˆ‘ä»¬å¯¹å¤šç§åŸºçº¿æ¨¡å‹ï¼ˆInstruct æ¨¡å‹ä¸ Guard æ¨¡å‹ï¼‰è¿›è¡Œäº†è¯„æµ‹ï¼Œå¹¶ä¸ **Libra Guard** çš„è¡¨ç°è¿›è¡Œäº†å¯¹æ¯”ã€‚  
*In the following table, we compare various baseline models (Instruct models and Guard models) against **Libra Guard**.*

| **Models**                       | **Average** | **Synthesis** | **Safety-Prompts** | **BeaverTails\_30k** |
|----------------------------------|-------------|---------------|--------------------|----------------------|
| **Instruct Models**              |             |               |                    |                      |
| Qwen-14B-Chat                    | 0.6883      | 0.5787        | 0.6886             | 0.7977               |
| Qwen2.5-0.5B-Instruct            | 0.6337      | 0.5740        | 0.6482             | 0.6790               |
| Qwen2.5-1.5B-Instruct            | 0.6530      | 0.5719        | 0.6648             | 0.7222               |
| Qwen2.5-3B-Instruct              | 0.7121      | 0.6360        | 0.7060             | 0.7944               |
| Qwen2.5-7B-Instruct              | 0.6249      | 0.5392        | 0.5563             | 0.7793               |
| Qwen2.5-14B-Instruct             | 0.7433      | 0.6810        | 0.6696             | 0.8793               |
| Yi-1.5-9B-Chat                   | 0.5174      | 0.4097        | 0.4334             | 0.7091               |
| GLM4-9B-Chat                     | 0.7220      | 0.6530        | 0.6727             | 0.8402               |
| **Guard Models**                 |             |               |                    |                      |
| Llama-Guard                      | 0.3961      | 0.3388        | 0.2845             | 0.5650               |
| ShieldGemma                      | 0.4403      | 0.4104        | 0.3154             | 0.5951               |
| ShieldLM                         | 0.6569      | 0.6196        | 0.5341             | 0.8171               |
| Libra-Guard-Qwen-14B-Chat        | 0.8648      | 0.8296        | 0.8534             | 0.9114               |
| Libra-Guard-Qwen2.5-0.5B-Instruct | 0.8146      | 0.7905        | 0.8223             | 0.8311               |
| Libra-Guard-Qwen2.5-1.5B-Instruct | 0.8392      | 0.7975        | 0.8376             | 0.8826               |
| Libra-Guard-Qwen2.5-3B-Instruct   | 0.8475      | 0.8153        | 0.8391             | 0.8880               |
| Libra-Guard-Qwen2.5-7B-Instruct   | 0.8524      | 0.8132        | 0.8471             | 0.8970               |
| Libra-Guard-Qwen2.5-14B-Instruct  | **0.8679**  | 0.8337        | 0.8597             | 0.9104               |
| Libra-Guard-Yi-1.5-9B-Chat        | 0.8593      | 0.8200        | 0.8645             | 0.8933               |

Libra Guard åœ¨å®‰å…¨æ£€æµ‹ä»»åŠ¡ä¸­æ˜¾è‘—ä¼˜äº Instruct å’Œ Guard åŸºçº¿ï¼Œå±•ç¤ºäº†å…¶åœ¨å¤šä¸ªåŸºå‡†å’Œæ•°æ®é›†ç±»å‹ä¸Šçš„å¼ºå¤§æ€§èƒ½ã€‚

*This table demonstrates that Libra Guard significantly outperforms both Instruct and Guard baselines in safety detection tasks, showcasing its robust performance across multiple benchmarks and dataset types.*

---

## ğŸ“Š Libra Bench

**Libra Bench** æ˜¯ä¸“ä¸ºä¸­æ–‡å¤§æ¨¡å‹å®‰å…¨æ€§è€Œæ„å»ºçš„è¯„æµ‹åŸºå‡†ï¼Œæ¶µç›–ä»¥ä¸‹ä¸‰ç§æ•°æ®æ¥æºå¹¶ç»è¿‡ä¸¥æ ¼çš„äººå·¥å®¡æ ¸ï¼š  

*Libra Bench is a safety benchmark designed for Chinese LLMs, containing real, synthetic, and translated data carefully verified by experts.*

1. **çœŸå®æ•°æ®ï¼ˆReal Dataï¼‰**  
2. **åˆæˆæ•°æ®ï¼ˆSynthetic Dataï¼‰**  
3. **ç¿»è¯‘æ•°æ®ï¼ˆTranslated Dataï¼‰**  

| **Type**          | **Safe** | **Unsafe** | **Total** |
|-------------------|----------|------------|-----------|
| Real Data         | 381      | 881        | 1,262     |
| Synthetic Data    | 583      | 884        | 1,467     |
| Translated Data   | 900      | 2,091      | 2,991     |
| **Total**         | **1,864**| **3,856**  | **5,720** |



---

## ğŸ“ å¼•ç”¨ (Citation)

å¦‚æœæœ¬é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ©ï¼Œè¯·å¼•ç”¨ä»¥ä¸‹è®ºæ–‡ï¼š  
*If this project is helpful to you, please cite the following papers:*

```bibtex
@article{chen2024libra,
  title={Libra Guard: Large Chinese-based Safeguard for AI Content},
  author={Chen, Ziyang and Yu, Huimu and Wu, Xing and Hu, Songlin},
  journal={arXiv preprint arXiv:XXXX.XXXXX},
  year={2024}
}
@inproceedings{chen2024libra,
    title = "{L}ibra {G}uard: A Large Chinese-based Safeguard for AI Content",
    author = "Chen, Ziyang and Yu, Huimu and Wu, Xing and Hu, Songlin",
    booktitle = "Proceedings of the XXXth Conference on Computational Linguistics",
    month = aug,
    year = "2024",
    address = "City, Country",
    publisher = "Association for Computational Linguistics",
    doi = "10.18653/v1/2024.conll-XXX.XXX",
    pages = "XXXX--XXXX",
}
```
